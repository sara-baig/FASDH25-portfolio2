# FASDH25-portfolio2
A repository for students' portfolios for mini-project 2
# Mini Project 2: Geographical Visualization of Gaza Placenames after War from January 2024 News Articles
This project withdraws and envisions geographic references from January 2024 news articles about Gaza. We used two different techniques: regular expressions with a gazetteer and Named Entity Recognition (NER) to compare place recognition.

## Folder Structure
- 'articles': Raw news articles from January 2024 in text format
- 'gazetteers': Contains TSV files
- 'Scripts': Scripts for regex+gazetteer extraction, and for NER using Stanza
- '2README.md': Project documentation
- 'ChatGPT Convos': Documentation of ChatGPT conversations

## Project Overflow
### Forking and Cloning the portfolio folder(0)
We began by creating an independent copy of the portfolio repository using a process called forking in Git. This allowed one person to contribute to the project without needing direct write access to the original repository or risking changes to the main project. One of our group members, Sara, forked the original portfolio repository. The other group members, Zehrish and Dilawaiz, then cloned Sara's fork to their local machines.
To do this, we opened Git Bash (or Terminal), navigated to the Downloads folder, and ran the command:
git clone https://github.com/sara-baig/FASDH25-portfolio2.git
This gave each of us a local copy of the forked GitHub repository, allowing us to work on the project and make changes independently on our own devices.

### Using gazetteer and regex to extract places in Gaza from the corpus(2A)
This script, regex_script_final.py, was developed to extract and analyze place names in Gaza mentioned in a large corpus of news articles. The primary objective was to improve recall when identifying place names using a gazetteer. To achieve this, Zehrish built the script of a regex pattern for each place that includes both the asciiname and all alternative names provided in the gazetteer, increasing the likelihood of matching differently spelled versions of the same place in the texts. It processed only those articles written after the Gaza war began on October 7, 2023, using dates embedded in filenames to filter accordingly. Each time a place was mentioned, it recorded and counted on a per-month basis, resulting in a nested dictionary structure that captured the frequency of mentions by month. The output was exported into a tab-separated values file, regex_counts.tsv, for external analysis.
To address issues encountered during development, some solutions were adapted with the help of ChatGPT. First, the output initially included a large number of columns with zero counts, making the results unnecessarily cluttered. A conditional check was added, sourced from ChatGPT aiming to skip entries with zero matches, thereby cleaning the output. Second, the initial output appeared overestimated due to overlapping or imprecise regex matches. A more accurate regex-building method, again with ChatGPT’s assistance, was implemented to improve precision and ensure that matches more closely reflect actual place name mentions in the text. These interventions helped refine the script’s accuracy and usability. Overall, this README serves as documentation for the functionality, logic, and external code assistance used to deliver a reliable regex-based place name extraction and counting tool.
This task done by Zehrish was lastly reviewed by Dilawaiz.

### Using stanza to extract all place names from (part of) the corpus(2B)
Sara contributed by making a copy of the Colab notebook we used in class, adapting it to extract and analyze place names from a large collection of news articles. The original notebook was renamed to Gaza_NER2_dilawaiz_sara_zehrish.ipynb to include the names of all group members, as per the project guidelines. One of the key modifications she made early on was replacing the original smaller sample corpus (from the “session_10.1” folder) with the full dataset available in our forked portfolio repository, allowing us to process a much more comprehensive and meaningful set of texts.
To make sure our analysis was focused on a specific timeframe, she implemented a filter so that the script only processed articles published in January 2024. This was done by checking for "2024-01" in the filename before applying the NLP pipeline. She used the Stanza library for this task, setting up an English language pipeline with processors for tokenization, multi-word token expansion, and Named Entity Recognition (NER). She specifically configured the NER system to detect only location-related entities, using Stanza’s built-in labels: GPE (Geo-Political Entity, such as cities or countries) and LOC (Location, such as mountains or rivers).
As the code iterated through each relevant article, it extracted place names and stored them in a dictionary along with their occurrence counts. However, Sara noticed inconsistencies, for example, both “Gaza” and “Gaza’s” were being counted as separate places, and entries like “The United States” were being duplicated due to differing capitalization and formatting. To solve this, she built a normalization process using regular expressions to remove possessive suffixes (’s), strip punctuation, and remove unnecessary leading words like “the”. This step greatly improved the accuracy of our counts by merging semantically identical entries under one clean label.
Finally, she saved the cleaned and normalized results in a TSV file named ner_counts.tsv, which contained two columns: Place and Count. This structured file was printed at the end of the notebook to verify its content and would later serve as the foundation for geocoding and map visualization in the next phase of our project.
Throughout the process, Sara asked ChatGPT for guidance at several critical steps. When she wasn’t sure how to filter articles by date, she confirmed with ChatGPT that checking if "2024-01" appeared in the filename would correctly isolate January 2024 articles. She also sought help on how to count place name mentions, and learned that using a dictionary with places[place] = places.get(place, 0) + 1 was the most efficient method. ChatGPT clarified why only GPE and LOC tags should be used in Stanza, and helped her figure out where exactly to insert the doc = nlp(text) line in her code (right after reading the file, before looping through entities).
As issues arose during data cleaning, ChatGPT also explained how to use regex like re.sub(r"[’']s\b", "", place) to remove possessives, and re.sub(r"^the\s+", "", place, flags=re.IGNORECASE) to strip leading articles like "The". Sara asked about tokenization and was reassured that the Stanza pipeline already handled tokenization and multi-word token expansion automatically. Lastly, ChatGPT helped her structure the code to write the final output to a TSV file, including a header and looping through the dictionary to write each row.
All of these interactions and problem-solving moments were captured in our ChatGPT history and became an important part of our collaborative learning process. Sara’s work laid the foundation for the geocoding and mapping stages, and her initiative in asking the right questions helped the whole team understand each step more deeply. Her contribution was crucial in building the core data extraction and cleaning pipeline that powered our group’s final visualization.
This task done by Sara was reviewed by Zehrish.

### Creating a gazetteer for the NER places(3)
Continuing from where the previous task left off, Dilawaiz took responsibility for Task 3 of our project, which focused on building a gazetteer by geocoding the place names extracted during the Named Entity Recognition (NER) process. Working in the same Colab notebook that had been used earlier for extracting and cleaning place names, she began by loading the finalized list of places from the ner_counts.tsv file. The goal of this task was to assign geographic coordinates (latitude and longitude) to each place name and create a structured reference file that could later be used for mapping and visualization.
To accomplish this, Dilawaiz wrote a function within the notebook that used the GeoNames API. The function, get_coordinates(), sent API requests for each place name and retrieved their geographic coordinates in JSON format. She also added a short time delay (time.sleep) between API calls to avoid overwhelming the server. For every place name, the script either extracted valid coordinates or marked the entry with "NA" if no match was found — allowing for future manual lookup.

She read the list of place names directly from ner_counts.tsv, skipped the header, and stored all the place names in a list. Then, using a loop, she passed each place name through the GeoNames function and wrote the results to a new TSV file called ner_gazetteer.tsv. This file included three columns: Name, Latitude, and Longitude. Places without coordinates (i.e., with "NA" values) were manually checked using Google Maps and updated as needed noted below:
"Dahiyeh\t33.853395052710695\t35.51072235686155\n",
"Shujayea\t31.50214418626344\t34.470334523798314\n",
"alSaftawi\tNA\tNA\n", removed 
"Houthis\tNA\tNA\n", removed
"alMahatta\t25.347248487453296\t55.39272980310503\n",
"alWalaja\t31.729975862724757\t35.15887300863969\n",
  "Supernova\tNA\tNA\n", removed
"AlAqsa\tNA\tNA\n",
"Rawaa\tNA\tNA\n",34.37156151693279, 35.793024424086155
"alKarama\tNA\tNA\n",25.251610263654864, 55.308566911925176
"alMawasi\tNA\tNA\n",31.349585715311555, 34.255620700573026
"alMaghazi\tNA\tNA\n",31.422537288514665, 34.38567317700257
"Beruit\tNA\tNA\n",33.892916341197115, 35.50033285884257
"Africa4Palestine\t-26.13854513460461\t28.017489995085203\n",
  "alMazraa Asharqiya\tNA\tNA\n",32.004982683201206, 35.275874194665086
"alNasser\t29.933035102867347\t47.612137838201946\n",
"alJiftlik\t32.15569658618502\t35.46985715767295\n",
"SistanBaluchestan\t28.499399317561767\t60.35549844568305\n",
"Bahaa\t27.029932263871547\t77.81456617515826\n",
"Mazzeh\t45.46812354367441\t-73.6509915752512\n",
"Palestine_UN\tNA\tNA\n",
"RedSea\t19.771587863376958\t39.109721465414374\n",
"alShifa\t24.914203527286965\t67.06989190267082\n",
"Taalbaya\t33.817917130442\t35.864149961862765\n",
"Zawayda\t31.43129883013029\t34.37065585426928\n",
"BosniaHerzegovina\t44.586118488170634\t17.672192147136673\n",
alFawakhir
"Balakhiyah\tNA\tNA\n",
"Balakhiyah\tNA\tNA\n",
"Ahmadiyyah Zawiya\t32.7638168517502\t12.738985310693632\n",
"Philadelphi\t29.9989839993305\t33.74637642842885\n",
"AlFukhari\t31.296912719336326\t34.332980023168155\n",
"alAhli\tNA\tNA\n",

To verify her output, Dilawaiz displayed the contents of ner_gazetteer.tsv directly in the Colab notebook. Throughout this task, Dilawaiz frequently consulted ChatGPT to troubleshoot and refine the geocoding pipeline. For instance, when deciding how to query the GeoNames API, she confirmed the structure of the get_coordinates() function and learned to avoid exceeding rate limits by adding time.sleep(1) between requests. To validate her function before scaling up, she tested it on a few sample places like “Gaza” and “Jerusalem.” When the API failed to return coordinates for entries like "Gaza’s" or "Al-Quds," ChatGPT advised implementing error handling with a try-except block to gracefully assign "NA" values, and later clean the inputs by removing possessives and punctuation. She also asked how to format the final output and was guided to write a properly structured TSV file with a header and tab-separated fields, saved as ner_gazetteer.tsv in the gazetteers/ folder. For entries that still returned "NA," ChatGPT recommended manual lookup using tools like Google Maps or Wikipedia and documenting these manual edits in a separate section titled Manual Geocoding Notes. These interactions played a key role in helping her complete the geocoding task efficiently and accurately.
Her work completed a crucial part of our data pipeline — converting place names into mappable geographic points — and prepared the dataset for the final visualization step of the project.
This task done by Dilawaiz was reviewed by Sara.

### Map the regex-extracted placenames(4a)
In this part of the project, mapping script was developed by Zehrish which visualized the frequency of regex-extracted place names using plotly.express. The key objective was to transform the raw count data from regex_counts.tsv into a dynamic, interpretable geographic map that reflected how often different places in Gaza were mentioned in the news corpus, month by month. To do this, the script first loaded and pre-processed two separate datasets: the gazetteer (containing geographical coordinates and place names) and the regex output (containing frequency data). A challenge emerged because the two datasets shared no exact common column. To resolve this, with guidance from ChatGPT, Zehrish learned how to merge dataframes based on comparable but differently named columns by normalizing the relevant fields, converting placename and asciiname to lowercase and stripping whitespace and then merging them using pd.merge() with the left_on and right_on arguments. This allowed the creation of a merged dataset that linked place frequencies with their geographical coordinates. Another issue eemerged while generating the maps. Though the map was correctly formed in PNG form but it was not showing up in the project portfolio. Additionally, it failed to generate map in HTML form. For this, the python suggested to intall Kaleido. Zehrish did this and everthing went well.
Several visualization strategies were explored to represent this data meaningfully. Initially, she used a static scatter map with a color scale (YlOrRd) indicating the frequency of mentions. This choice offered clear visual contrast, helping highlight the most discussed locations. To further refine the visual aesthetics, she adjusted the background using the carto-darkmatter-nolabels map style and configured the geo-projection to ‘natural earth’, enabling a more readable global context. Colors for land, ocean, and rivers were customized to enhance clarity. However, a static map proved insufficient for capturing temporal dynamics. Therefore, Zehrish created an animated scatter map using the animation_frame parameter set to "month", allowing the viewer to observe changes in place name frequencies over time. The size of the points were scaled according to frequency, and the same color scale was retained for consistency.
This dual-approach of combining static and animated mapping proved effective in conveying both spatial distribution and temporal trends. The interactive version was saved as regex_map.html for browser-based viewing, and a high-resolution static image was exported as regex_map.png. Overall, the assistance from ChatGPT was instrumental in resolving technical obstacles such as non-matching dataframe structures, and in refining regex preprocessing logic. The result was a compelling, interactive visualization that bridged geographic and temporal dimensions of place name mentions in Gaza.
This task done by Zehrish was reviewed by both Sara and Dilawaiz.

### Map the NER-extracted placenames(4b)
Both Dilawaiz and Sara worked together to visualize the frequency of NER-extracted place names from January 2024 on an interactive map. This task involved using the cleaned data files generated in earlier steps: ner_counts.tsv (which held the frequency of each location extracted from the corpus) and ner_gazetteer.tsv (which contained the geocoded coordinates for those places). Their objective was to plot each place on a map using Plotly Express and size the markers based on how frequently each place was mentioned.

They began by importing the required libraries, primarily pandas for handling tabular data and plotly.express for creating geographic scatter plots. Both .tsv files were loaded into pandas dataframes, and the next step involved merging them on their respective place name columns — "Place" in the counts file and "Name" in the gazetteer. This merge operation was crucial, and during the process, the group consulted ChatGPT for help. When asked how to join the two .tsv files, ChatGPT suggested using pandas.merge() and explained how this function works similarly to a join operation in Excel.

Once merged, some rows were found to contain missing coordinates (NA values), and ChatGPT confirmed that dropping these rows using dropna(subset=["Latitude", "Longitude", "Count"]) was a good way to avoid plotting errors. After cleaning the data, they encountered another technical hurdle — the values in the "Latitude", "Longitude", and "Count" columns were being read as strings instead of numbers. When they asked ChatGPT why conversion to float was necessary, it clarified that Plotly requires numeric types to correctly interpret positions and marker sizes. As a result, the team used .astype(float) to convert all relevant columns.

With the data properly cleaned and formatted, the map was created using plotly.express.scatter_geo(). The latitude and longitude determined where each point would appear, the size="Count" parameter visually represented how frequently each place name was mentioned, and color="Place" helped distinguish locations using different shades. In another ChatGPT consultation, the team confirmed that using both size and color this way was appropriate and enhanced the interpretability of the map.

Finally, they exported the map using fig.write_html("ner_map.html") for an interactive version and fig.write_image("ner_map.png") for a static image, ensuring compatibility with both online and print-based presentations. There was a issue of failure to generate map in HTML form. For this, the python suggested to intall Kaleido which we did.

By the end of Task 4B, Dilawaiz and Sara had successfully created an interactive map that visually communicated the spatial distribution and frequency of place names extracted from news articles published in January 2024. Their consistent use of external resources like ChatGPT also demonstrated their proactive approach to problem-solving and technical troubleshooting throughout the process.
This task done by Sara and Dilawaiz was finally reviewed by Zehrish.

### Finalizing the portfolio folder(5) and Uploading to Moodle(6)
This phase involved consolidating all scripts, outputs, visualizations, and documentation into a clean, well-organized repository that reflects the structure and workflow of our project. We began by creating a folder structure that kept our files organized and easy to navigate. At the top level of the repository, we included key output files and documentation, such as:
README.md — this main file describing the scope, methodology, and outcomes of our project.
regex_counts.tsv — the output of our regex extraction script, containing term frequency data.
regex_script_final.py — the finalized Python script used for regex pattern extraction from articles.
Gaza_NER2_dilawaiz_sara_zehrish.ipynb — our Colab notebook for extracting and normalizing place names using Stanza.
NER_gazetteer.tsv — a tab-separated file listing place names and their corresponding coordinates.
build_gazetteer.py (or .ipynb) — the script that queries the GeoNames API and generates the gazetteer.
regex_map.html and regex_map.png — interactive and static maps visualizing regex-extracted terms.
ner_map.html and ner_map.png — similar maps showing the geographic spread of NER-extracted places.
A gazetteers/ folder to store the generated NER_gazetteer.tsv and any related files.
An articles/ folder containing the full dataset of news articles.
A scripts/ folder to store all Python files in one place for clarity.

####Documentation and AI Reflections
Each group member created a personal AI document, e.g., AI_documentation_SaraBaig.docx file, reflecting on how ChatGPT was used during the project. Instead of relying on ChatGPT to generate answers, we used it as a learning companion by asking it to explain concepts, help debug code, and walk us through best practices.

####Final Preparation and Uploading to Moodle
Once our GitHub repository was complete and reviewed, we created a local copy of it on one team member’s computer. Following the submission guidelines, we deleted the articles/ folder (which contained a large volume of raw text data) and the hidden .git/ directory (to reduce file size and remove versioning metadata).
We then zipped the entire folder using standard compression tools and uploaded it to Moodle. Alongside the zip file, we also submitted the link to our public GitHub fork, allowing instructors to access the full project history, including commit messages and notebook versions.
This two-step submission—GitHub link for transparency and zipped folder for portability—ensured that our project could be reviewed both as a final product and as a documented process.
The finalization stage helped us synthesize our work and understand how small decisions in naming conventions, folder structure, and file formatting impact clarity and usability. By organizing our portfolio thoughtfully and reflecting on our use of tools like ChatGPT, we demonstrated not just technical skills but also collaborative project management and ethical engagement with AI support.


## Comparison: Regex + Gazetteer vs NER
###Regex + Gazetteer:
Pros: One of the primary advantages of using regex with a gazetteer is its high precision when dealing with known place names. By using a curated list of Gaza-related locations (the gazetteer), we could match exact terms in the text using regex patterns. This method is particularly effective for domains where terminology is consistent and relatively constrained. Moreover, regex is computationally efficient, easily implemented, and transparent, making the results interpretable and easy to debug. When we needed to filter out irrelevant data or match specific formats (e.g., words in uppercase or within particular sentence structures), regex allowed fine-grained control.
Cons: This method has clear limitations. It is entirely rule-based and thus lacks flexibility. If a place name is spelled differently, abbreviated, or mentioned in a context not anticipated by the regex rules, it will be missed. Moreover, the gazetteer needs to be comprehensive and updated—any omissions directly lead to false negatives. It also lacks the ability to handle context; for example, a word like “Rafah” might be a person’s name in one context and a location in another, but regex has no way of distinguishing between the two. In our project, we noticed this rigidity when uncommon or misspelled place names were missed entirely.

###NER (Stanza)
Pros: NER, particularly through the Stanza NLP library, offers a more context-aware and generalizable approach. It identifies place names based on linguistic features and learned patterns, rather than static lists. This meant that it could detect previously unseen place names or capture locations even if they were embedded in complex sentence structures. For example, Stanza could identify “the southern city of Khan Younis” as a location, even without a direct match in the gazetteer. This was particularly useful given the wide variety of reporting styles across the news articles.
Cons: NER also has drawbacks. Its accuracy is dependent on the quality and domain-alignment of its training data. Stanza, although state-of-the-art, is trained on general corpora and may underperform on specialized or region-specific text. In our experience, this led to some false positives, where the model misidentified organizations or adjectives as place names. Additionally, NER models are computationally heavier than regex and less transparent; errors are harder to trace and correct since they stem from the model's learned weights rather than explicit rules.

## Final Maps
### Regex-based Map
![image]("FASDH25-portfolio2\Outputs\Maps\regex_map.png.png")

### NER-based Map
![image]("FASDH25-portfolio2\Outputs\Maps\ner_map.png.png")]

##Comparison of Maps
The comparison between the regex-based and NER-based maps for January 2024 reveals key differences in both extraction methodology and visualization outcomes. The regex-based approach relies on a predefined list of place names stored in a gazetteer. This list is then matched against the article texts using regular expressions, allowing for highly controlled and precise matching. However, this precision comes at the cost of flexibility. If a place is mentioned using a slightly different spelling, variation, or possessive form (e.g., “Gaza’s”), the regex might not detect it unless those variants were anticipated and explicitly listed in the gazetteer. As a result, the regex map tends to be more limited in its geographic coverage, with fewer data points plotted, especially if the gazetteer was not exhaustive or updated. This map gives a cleaner, more conservative representation of place mentions but may underrepresent the full range of locations discussed in the articles.
In contrast, the NER-based map uses Stanza’s named entity recognition to dynamically extract all entities classified as GPE (Geo-Political Entity) or LOC (Location) from the January 2024 news corpus. This approach does not depend on a static list; instead, it leverages machine learning to recognize contextually relevant place names, even if they appear in varied grammatical forms or are previously unseen. Consequently, the NER approach results in a significantly higher number of recognized places, offering a much broader and more detailed map. However, this inclusivity introduces its own issues. Some non-places or incorrectly tagged entities (e.g., Twitter handles, abstract regions like “Middle East Eye,” or duplicated variants like “the Gaza Strip” and “Gaza”) might appear, especially if not cleaned properly. This leads to a noisier map with potential overlaps and inconsistencies.
Another key visual difference lies in the distribution and density of points. The NER map shows denser clustering, particularly in conflict zones such as Gaza, Tel Aviv, and the West Bank. Marker sizes in this map, scaled by frequency of mentions, highlight which regions were most frequently discussed in January 2024. By contrast, the regex map, due to its more constrained matching, shows fewer locations and potentially overlooks emergent or less-expected geographic references. The NER map also visualizes more international mentions—places like Washington DC, Doha, and Tehran—which the regex method might have missed unless manually included in the gazetteer.
Finally, in terms of project goals, the NER map offers greater value for exploratory analysis or when capturing a wider picture of narrative scope is essential. The regex map, on the other hand, is better suited for targeted tracking of specific known places. The maps together underscore a fundamental trade-off between control and coverage. Ideally, combining both approaches—using regex for precision and NER for discovery—can provide a more balanced geographical visualization. Overall, the NER-based map provides a richer, though messier, insight into the geopolitical references in the January 2024 articles, while the regex map offers a clean, focused subset grounded in a known place list.

## Limitations and Improvements
While our project, “Geographical Visualization of Gaza Placenames after War from January 2024 News Articles”, achieved its central objectives of extracting, geocoding, and mapping place names from news corpora using both regex and NER techniques, several weaknesses and limitations remain. A more extended timeline or additional resources could have significantly improved the precision, coverage, and interpretability of our outputs.

One key limitation lies in the regex-based extraction method. Although regex paired with a gazetteer yielded high precision for known place names, the method was rigid and inherently limited by the comprehensiveness of the gazetteer itself. Any place not included — whether due to alternative spellings, abbreviations, or omissions — was missed entirely. As such, the method showed poor recall. In several cases, places mentioned in news reports were skipped because our regex patterns couldn’t account for unexpected variations. While we attempted to address this by building broader regex patterns that included alternate names and cleaned the matches to avoid overcounting, the process was still manually intensive and error-prone. If given more time, we would have explored fuzzy matching or hybrid methods combining regex with partial NER validation to improve both coverage and flexibility.

In contrast, the NER-based extraction using Stanza provided more generalizability and discovered place names not present in our gazetteer. However, it introduced its own set of issues. Since Stanza’s NER model is trained on general corpora, it sometimes misidentified non-place entities (e.g., “Welch,” “West”) as locations. Furthermore, the model treated minor variations like “Gaza’s” and “The United States” as distinct entities, resulting in duplication and cluttered outputs. Although we implemented normalization steps to clean possessives and leading articles, inconsistencies likely remain. A better pre-trained model fine-tuned on Middle Eastern geopolitical news would likely have performed better. Additionally, we could have explored ensemble NER models or added a human validation step to the entity list if we had more time.

The visualizations themselves, though functional, exposed deeper challenges. The regex-based map, while visually sharp and temporally rich (with monthly animation), was restricted to the Gaza region and didn’t offer broader geopolitical context. Conversely, the NER map, while global in scope, presented a flatter, non-animated static view of January 2024 alone. Its color coding by category became overwhelming with many entities, and it lacked a sense of frequency gradient. Marker overlap made it harder to visually interpret high-density regions. With more time, we could have synchronized both maps into a dual-mode dashboard allowing users to toggle between regex and NER layers interactively. We also would have included more meaningful legends, hover details (like article sources or dates), and better scaling of marker sizes for clarity.

Geocoding posed another serious bottleneck. Although we automated much of the process via the GeoNames API, many locations returned “NA” due to spelling issues or API limitations. We had to perform several manual lookups for obscure or misformatted place names. This was time-consuming and likely still incomplete. Some entries with missing or incorrect coordinates were dropped from the maps, thus affecting coverage. With more time, we could have implemented fuzzy matching during geocoding or cross-referenced multiple APIs (like Google Maps and Wikipedia coordinates) to improve coverage and accuracy. Additionally, documenting these lookups systematically earlier in the process would have helped streamline manual verification.

Lastly, while our use of Git, Colab, and team collaboration was effective overall, it occasionally lacked versioning discipline. Some scripts were updated directly without structured branching or pull requests. A more disciplined version control practice would have allowed better traceability of changes and smoother group collaboration. Also, while our ChatGPT documentation was thorough, we could have explored more AI tools (like OpenRefine or spaCy) for data cleaning and entity classification if time permitted.

In conclusion, the project provided a solid foundation in digital humanities methodology, but its current limitations — from rigid extraction, inconsistent normalization, partial geocoding, and isolated visual outputs — highlight clear areas for growth. With more time and iteration, we would aim for a more robust, context-aware, and interactive system that better captures the geographical and temporal complexity of the Gaza conflict narrative.
